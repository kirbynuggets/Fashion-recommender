{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# Configuration (Feel free to modify these)\n",
    "CSV_FILE = '../../datasets/styles_fixed.csv'  # Path to your CSV file.\n",
    "IMAGE_DIR = 'static/high_res_images'     # Directory containing images.\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 1\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# 1. Data Loading and Preprocessing\n",
    "\n",
    "class ApparelDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None, target_attributes=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (pd.DataFrame): DataFrame containing image metadata.\n",
    "            image_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            target_attributes (list):  List of attribute names to predict (e.g., ['gender', 'articleType']).\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.target_attributes = target_attributes\n",
    "        self.label_encoders = {}\n",
    "\n",
    "        # Initialize LabelEncoders for each target attribute\n",
    "        for attr in self.target_attributes:\n",
    "          if attr in self.dataframe.columns:  # Make sure attribute exists\n",
    "            le = LabelEncoder()\n",
    "            # Handle missing values by replacing with a placeholder string\n",
    "            self.dataframe[attr] = self.dataframe[attr].astype(str).fillna('Unknown')\n",
    "            # Fit and transform the labels\n",
    "            self.dataframe[attr] = le.fit_transform(self.dataframe[attr])\n",
    "            self.label_encoders[attr] = le\n",
    "          else:\n",
    "            print(f\"Warning: Attribute '{attr}' not found in DataFrame.\")\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.dataframe.iloc[idx]['id']\n",
    "        img_name = os.path.join(self.image_dir, f\"{img_id}.jpg\")\n",
    "        try:\n",
    "            image = Image.open(img_name).convert('RGB')  # Load image and convert to RGB\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Image file not found: {img_name}\")\n",
    "            # Return a black image as a placeholder\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Create a dictionary of labels for each target attribute\n",
    "        labels = {}\n",
    "        for attr in self.target_attributes:\n",
    "            if attr in self.dataframe.columns:  # Check if the attribute exists\n",
    "                labels[attr] = torch.tensor(self.dataframe.iloc[idx][attr], dtype=torch.long)\n",
    "            else:\n",
    "                labels[attr] = torch.tensor(-1, dtype=torch.long) # Assign a dummy value\n",
    "\n",
    "        return image, labels\n",
    "\n",
    "\n",
    "\n",
    "# Load the CSV (handling errors and limiting rows for faster prototyping)\n",
    "try:\n",
    "    data = pd.read_csv(CSV_FILE) #, error_bad_lines=False, warn_bad_lines=True, nrows=1000)  # Read fewer rows at first.\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {CSV_FILE}\")\n",
    "    exit()\n",
    "except pd.errors.ParserError:\n",
    "    print(f\"Error: Parsing error in CSV file {CSV_FILE}\")\n",
    "    exit()\n",
    "\n",
    "# Drop rows with missing IDs\n",
    "data.dropna(subset=['id'], inplace=True)\n",
    "\n",
    "# Check for the existence of the images directory\n",
    "if not os.path.isdir(IMAGE_DIR):\n",
    "    print(f\"Error: Image directory '{IMAGE_DIR}' not found.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Select target attributes (you can add/remove attributes here)\n",
    "target_attributes = ['gender', 'articleType', 'baseColour', 'season', 'usage']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "\n",
    "# Image transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "        'test': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ApparelDataset(train_df, IMAGE_DIR, data_transforms['train'], target_attributes)\n",
    "val_dataset = ApparelDataset(val_df, IMAGE_DIR, data_transforms['val'], target_attributes)\n",
    "test_dataset = ApparelDataset(test_df, IMAGE_DIR, data_transforms['test'], target_attributes)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# 2. Model Definition (Multi-Task Classifier)\n",
    "class MultiTaskClassifier(nn.Module):\n",
    "    def __init__(self, num_classes_dict):\n",
    "        super(MultiTaskClassifier, self).__init__()\n",
    "        # Use a pre-trained ResNet model\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        in_features = self.base_model.fc.in_features\n",
    "\n",
    "        # Remove the original fully connected layer\n",
    "        self.base_model.fc = nn.Identity()  # Replace with Identity to act as feature extractor\n",
    "\n",
    "        # Create separate classification heads for each attribute\n",
    "        self.heads = nn.ModuleDict({\n",
    "            attr: nn.Linear(in_features, num_classes) for attr, num_classes in num_classes_dict.items()\n",
    "        })\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)  # Get features from ResNet\n",
    "        outputs = {attr: head(x) for attr, head in self.heads.items()}\n",
    "        return outputs\n",
    "\n",
    "# Calculate the number of classes for each target attribute\n",
    "num_classes_dict = {attr: len(train_dataset.label_encoders[attr].classes_) for attr in target_attributes if attr in train_dataset.label_encoders}\n",
    "print(f\"Number of classes for each attribute: {num_classes_dict}\")\n",
    "\n",
    "# Instantiate the model\n",
    "model = MultiTaskClassifier(num_classes_dict).to(DEVICE)\n",
    "\n",
    "\n",
    "# 3. Loss Function and Optimizer\n",
    "# Loss Function:  CrossEntropyLoss for each classification head\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Learning Rate Scheduler (Optional - but generally good practice)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# 4. Training Loop\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = {attr: 0.0 for attr in target_attributes} #track best accuracy for each attribute\n",
    "\n",
    "    for epoch in trange(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dataloader = val_loader\n",
    "\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = {attr: 0 for attr in target_attributes} #track corrects for each attribute\n",
    "            total_samples = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloader):\n",
    "                inputs = inputs.to(DEVICE)\n",
    "\n",
    "                # Convert labels to a dictionary of tensors and move to the device\n",
    "                labels_dict = {attr: labels[attr].to(DEVICE) for attr in target_attributes if attr in labels}\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = 0\n",
    "                    for attr in target_attributes:\n",
    "                         if attr in labels_dict and attr in outputs: #Check if attribute is present\n",
    "                            loss += criterion(outputs[attr], labels_dict[attr])\n",
    "                            _, preds = torch.max(outputs[attr], 1)\n",
    "                            running_corrects[attr] += torch.sum(preds == labels_dict[attr].data)\n",
    "\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                total_samples += inputs.size(0)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step() # Update learning rate\n",
    "\n",
    "            epoch_loss = running_loss / total_samples\n",
    "            epoch_acc = {attr: running_corrects[attr].double().item() / total_samples for attr in target_attributes if attr in running_corrects}\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {}'.format(\n",
    "                phase, epoch_loss, \", \".join([f\"{attr}: {epoch_acc[attr]:.4f}\" for attr in epoch_acc])))\n",
    "\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val':\n",
    "              for attr in target_attributes:\n",
    "                if attr in epoch_acc and epoch_acc[attr] > best_acc[attr]:  # Check if attr exists in both dicts\n",
    "                    best_acc[attr] = epoch_acc[attr]\n",
    "                    best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {}'.format(\", \".join([f\"{attr}: {best_acc[attr]:.4f}\" for attr in best_acc])))\n",
    "\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = train_model(model, criterion, optimizer, scheduler, num_epochs=NUM_EPOCHS)\n",
    "\n",
    "\n",
    "\n",
    "# 5. Evaluation\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    running_corrects = {attr: 0 for attr in target_attributes}\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels_dict = {attr: labels[attr].to(DEVICE) for attr in target_attributes if attr in labels}\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            for attr in target_attributes:\n",
    "                if attr in labels_dict and attr in outputs:\n",
    "                  _, preds = torch.max(outputs[attr], 1)\n",
    "                  running_corrects[attr] += torch.sum(preds == labels_dict[attr].data)\n",
    "\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "    accuracy = {attr: running_corrects[attr].double().item() / total_samples for attr in target_attributes if attr in running_corrects}\n",
    "    print('Accuracy on the test set:')\n",
    "    for attr in target_attributes:\n",
    "       if attr in accuracy:\n",
    "        print(f'{attr}: {accuracy[attr]:.4f}')\n",
    "\n",
    "\n",
    "evaluate_model(model, test_loader)\n",
    "\n",
    "\n",
    "# 6.  Prediction on a Single Image (Inference)\n",
    "def predict_single_image(model, image_path, transform, label_encoders):\n",
    "    \"\"\"Predicts attributes of a single image.\n",
    "\n",
    "    Args:\n",
    "        model: Trained PyTorch model.\n",
    "        image_path: Path to the image file.\n",
    "        transform: Image transformation pipeline.\n",
    "        label_encoders: Dictionary of LabelEncoders used during training.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image not found at {image_path}\")\n",
    "        return None\n",
    "\n",
    "    image = transform(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension [1, C, H, W]\n",
    "    image = image.to(DEVICE)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "\n",
    "    predictions = {}\n",
    "    for attr in label_encoders:\n",
    "        if attr in outputs:  # Check if the attribute head exists.\n",
    "           _, predicted_class = torch.max(outputs[attr], 1)\n",
    "           predicted_label = label_encoders[attr].inverse_transform(predicted_class.cpu().numpy())[0]\n",
    "           predictions[attr] = predicted_label\n",
    "        else:\n",
    "            predictions[attr] = \"N/A\"  # Attribute not predicted by the model\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Example usage of single image prediction:\n",
    "image_to_predict = 'images/10017.jpg' # Replace with your image path\n",
    "if os.path.exists(image_to_predict):  #check if the file exists\n",
    "    predictions = predict_single_image(model, image_to_predict, data_transforms['test'], train_dataset.label_encoders)\n",
    "\n",
    "    print(f\"Predictions for {image_to_predict}:\")\n",
    "    for attr, value in predictions.items():\n",
    "        print(f\"  {attr}: {value}\")\n",
    "else:\n",
    "\tprint(f\"Image file {image_to_predict} not found.  Skipping single image prediction.\")\n",
    "\n",
    "\n",
    "# 7. Save and load the model (Optional)\n",
    "torch.save(model.state_dict(), 'apparel_classifier.pth')\n",
    "\n",
    "# To load:\n",
    "# loaded_model = MultiTaskClassifier(num_classes_dict)  # Same architecture!\n",
    "# loaded_model.load_state_dict(torch.load('apparel_classifier.pth'))\n",
    "# loaded_model.to(DEVICE)\n",
    "# loaded_model.eval()  # Important: set to eval mode for inference!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
